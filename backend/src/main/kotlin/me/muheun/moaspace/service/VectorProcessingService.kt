package me.muheun.moaspace.service

import me.muheun.moaspace.domain.VectorChunk
import me.muheun.moaspace.event.VectorIndexingRequestedEvent
import me.muheun.moaspace.repository.VectorChunkRepository
import kotlinx.coroutines.*
import org.slf4j.LoggerFactory
import org.springframework.context.event.EventListener
import org.springframework.scheduling.annotation.Async
import org.springframework.stereotype.Service
import org.springframework.transaction.annotation.Propagation
import org.springframework.transaction.annotation.Transactional

/**
 * ë²”ìš© ë²¡í„° ì²˜ë¦¬ ì„œë¹„ìŠ¤
 *
 * VectorIndexingRequestedEventë¥¼ ìˆ˜ì‹ í•˜ì—¬ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë²¡í„° ìƒì„± ë° ì²­í¬ ì €ì¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 */
@Service
class VectorProcessingService(
    private val vectorChunkRepository: VectorChunkRepository,
    private val vectorService: VectorEmbeddingService,
    private val tokenizerService: TokenizerService
) {

    private val logger = LoggerFactory.getLogger(javaClass)

    companion object {
        private const val MAX_TOKENS_PER_CHUNK = 512
        private const val TARGET_TOKENS_PER_CHUNK = 256
    }

    /**
     * ë²¡í„° ì¸ë±ì‹± ìš”ì²­ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
     *
     * ê° í•„ë“œë³„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹í•˜ê³  ë³‘ë ¬ë¡œ ë²¡í„°ë¥¼ ìƒì„±í•œ í›„ DBì— ì €ì¥í•©ë‹ˆë‹¤.
     */
    @EventListener
    @Async
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    fun handleVectorIndexingRequest(event: VectorIndexingRequestedEvent) {
        try {
            logger.info("ğŸ”µ [ë²”ìš© ì¸ë±ì‹±] ì´ë²¤íŠ¸ ìˆ˜ì‹ : namespace=${event.namespace}, entity=${event.entity}, recordKey=${event.recordKey}, fields=${event.fields.keys}")

            event.fields.forEach { (fieldName, fieldValue) ->
                processFieldVectorization(
                    namespace = event.namespace,
                    entity = event.entity,
                    recordKey = event.recordKey,
                    fieldName = fieldName,
                    fieldValue = fieldValue,
                    metadata = event.metadata
                )
            }

            logger.info("âœ… [ë²”ìš© ì¸ë±ì‹±] ì™„ë£Œ: namespace=${event.namespace}, entity=${event.entity}, recordKey=${event.recordKey}")

        } catch (e: Exception) {
            logger.error("âŒ [ë²”ìš© ì¸ë±ì‹±] ì‹¤íŒ¨: namespace=${event.namespace}, entity=${event.entity}, recordKey=${event.recordKey}, error=${e.message}", e)
        }
    }

    /**
     * ê°œë³„ í•„ë“œì˜ ë²¡í„°í™” ì²˜ë¦¬
     *
     * í…ŒìŠ¤íŠ¸ì—ì„œ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ internalë¡œ ê³µê°œë©ë‹ˆë‹¤.
     */
    internal fun processFieldVectorization(
        namespace: String,
        entity: String,
        recordKey: String,
        fieldName: String,
        fieldValue: String,
        metadata: Map<String, Any>?
    ) {
        try {
            logger.debug("ğŸŸ¡ [í•„ë“œ ë²¡í„°í™”] ì‹œì‘: $entity.$fieldName (recordKey=$recordKey, í…ìŠ¤íŠ¸ ê¸¸ì´=${fieldValue.length})")

            val chunks = chunkText(fieldValue)
            logger.debug("ğŸŸ¢ [ì²­í‚¹ ì™„ë£Œ] $entity.$fieldName: ${chunks.size}ê°œ ì²­í¬ ìƒì„±")

            val vectorChunks = runBlocking {
                chunks.mapIndexed { index, chunkText ->
                    async(Dispatchers.IO) {
                        val vector = vectorService.generateEmbedding(chunkText)

                        VectorChunk(
                            namespace = namespace,
                            entity = entity,
                            recordKey = recordKey,
                            fieldName = fieldName,
                            chunkText = chunkText,
                            chunkVector = vector,
                            chunkIndex = index,
                            startPosition = 0,
                            endPosition = chunkText.length,
                            metadata = metadata
                        )
                    }
                }.awaitAll()
            }

            vectorChunkRepository.saveAll(vectorChunks)

            logger.debug("âœ… [í•„ë“œ ë²¡í„°í™”] ì™„ë£Œ: $entity.$fieldName (${chunks.size}ê°œ ì²­í¬ DB ì €ì¥)")

        } catch (e: Exception) {
            logger.error("âŒ [í•„ë“œ ë²¡í„°í™”] ì‹¤íŒ¨: $entity.$fieldName (recordKey=$recordKey), error=${e.message}", e)
            throw e
        }
    }

    /**
     * í…ìŠ¤íŠ¸ë¥¼ í† í° ê¸°ë°˜ìœ¼ë¡œ ì²­í‚¹
     *
     * ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•˜ê³  TARGET_TOKENS_PER_CHUNKë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
     */
    private fun chunkText(text: String): List<String> {
        if (text.isBlank()) return emptyList()

        val totalTokens = tokenizerService.countTokens(text)

        if (totalTokens <= TARGET_TOKENS_PER_CHUNK) {
            return listOf(text.trim())
        }

        val sentences = splitIntoSentences(text)
        val chunks = mutableListOf<String>()
        val currentChunk = StringBuilder()
        var currentTokenCount = 0

        for (sentence in sentences) {
            val sentenceTokens = tokenizerService.countTokens(sentence)

            if (sentenceTokens > MAX_TOKENS_PER_CHUNK) {
                if (currentChunk.isNotEmpty()) {
                    chunks.add(currentChunk.toString().trim())
                    currentChunk.clear()
                    currentTokenCount = 0
                }

                val truncated = tokenizerService.truncateToTokenLimit(sentence, MAX_TOKENS_PER_CHUNK)
                chunks.add(truncated)
                continue
            }

            if (currentTokenCount + sentenceTokens > TARGET_TOKENS_PER_CHUNK && currentChunk.isNotEmpty()) {
                chunks.add(currentChunk.toString().trim())
                currentChunk.clear()
                currentTokenCount = 0
            }

            currentChunk.append(sentence).append(" ")
            currentTokenCount += sentenceTokens
        }

        if (currentChunk.isNotEmpty()) {
            chunks.add(currentChunk.toString().trim())
        }

        return chunks
    }

    /**
     * í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
     */
    private fun splitIntoSentences(text: String): List<String> {
        val sentencePattern = Regex("""[^.!?]*[.!?]+""")
        val matches = sentencePattern.findAll(text)
        val sentences = matches.map { it.value.trim() }.filter { it.isNotBlank() }.toList()

        if (sentences.isEmpty()) {
            return listOf(text.trim())
        }

        val lastMatchEnd = matches.lastOrNull()?.range?.last ?: -1
        if (lastMatchEnd < text.length - 1) {
            val remaining = text.substring(lastMatchEnd + 1).trim()
            if (remaining.isNotBlank()) {
                return sentences + remaining
            }
        }

        return sentences
    }
}
