package me.muheun.moaspace.prototype

import org.junit.jupiter.api.DisplayName
import org.junit.jupiter.api.Test
import org.openkoreantext.processor.OpenKoreanTextProcessorJava
import org.openkoreantext.processor.tokenizer.KoreanTokenizer
import scala.collection.Seq
import org.assertj.core.api.Assertions.assertThat

/**
 * T002: í˜•íƒœì†Œ ë¶„ì„ ê¸°ë³¸ í…ŒìŠ¤íŠ¸
 *
 * Open Korean Textë¥¼ ì‚¬ìš©í•œ í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ ê¸°ë³¸ ë™ì‘ì„ ê²€ì¦í•©ë‹ˆë‹¤.
 *
 * **Acceptance Criteria:**
 * - í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ê·œí™” ë™ì‘ í™•ì¸
 * - í† í°í™” ë™ì‘ í™•ì¸
 * - ëª…ì‚¬ ì¶”ì¶œ ë™ì‘ í™•ì¸
 * - í˜¼í•© í…ìŠ¤íŠ¸(í•œêµ­ì–´+ì˜ì–´) ì²˜ë¦¬ í™•ì¸
 */
@DisplayName("[T002] í˜•íƒœì†Œ ë¶„ì„ í”„ë¡œí† íƒ€ì… í…ŒìŠ¤íŠ¸")
class MorphologyPrototypeTest {

    @Test
    @DisplayName("AC1: í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ê·œí™”ê°€ ì •ìƒ ë™ì‘í•´ì•¼ í•œë‹¤")
    fun `should normalize Korean text`() {
        // given
        val text = "í•œêµ­ì–´ã…‹ã…‹ã…‹ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤!!!"

        // when
        val normalized = OpenKoreanTextProcessorJava.normalize(text)
        val result = normalized.toString()

        // then
        println("ğŸ“Š [AC1] ì •ê·œí™” í…ŒìŠ¤íŠ¸:")
        println("  - ì›ë³¸: \"$text\"")
        println("  - ì •ê·œí™”: \"$result\"")

        assertThat(result).isNotBlank()
        // ì •ê·œí™”ëŠ” ì´ëª¨í‹°ì½˜ ì œê±°, ë°˜ë³µ ë¬¸ì ì¶•ì•½ ë“±ì„ ìˆ˜í–‰
        assertThat(result).doesNotContain("ã…‹ã…‹ã…‹")
    }

    @Test
    @DisplayName("AC2: í•œêµ­ì–´ í…ìŠ¤íŠ¸ í† í°í™”ê°€ ì •ìƒ ë™ì‘í•´ì•¼ í•œë‹¤")
    fun `should tokenize Korean text`() {
        // given
        val text = "Spring BootëŠ” Java ê¸°ë°˜ì˜ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤"

        // when
        val normalized = OpenKoreanTextProcessorJava.normalize(text)
        val tokens = OpenKoreanTextProcessorJava.tokenize(normalized)

        // Scala Seqë¥¼ Java Listë¡œ ë³€í™˜
        val tokenList = scala.collection.JavaConverters.seqAsJavaList(tokens)

        // then
        println("ğŸ“Š [AC2] í† í°í™” í…ŒìŠ¤íŠ¸:")
        println("  - ì›ë³¸: \"$text\"")
        println("  - í† í° ìˆ˜: ${tokenList.size}")
        println("  - í† í° ëª©ë¡:")
        tokenList.forEach { token ->
            println("    * ${token.text()} (${token.pos()})")
        }

        assertThat(tokenList).isNotEmpty
        assertThat(tokenList.size).isGreaterThan(5)
    }

    @Test
    @DisplayName("AC3: í•œêµ­ì–´ ëª…ì‚¬ ì¶”ì¶œì´ ì •ìƒ ë™ì‘í•´ì•¼ í•œë‹¤")
    fun `should extract Korean nouns`() {
        // given
        val text = "ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì‹œìŠ¤í…œ"

        // when
        val normalized = OpenKoreanTextProcessorJava.normalize(text)
        val tokens = OpenKoreanTextProcessorJava.tokenize(normalized)

        // ëª…ì‚¬ ì¶”ì¶œ (Noun, ProperNoun)
        val tokenList = scala.collection.JavaConverters.seqAsJavaList(tokens)
        val nouns = tokenList
            .filter { token ->
                val pos = token.pos().toString()
                pos == "Noun" || pos == "ProperNoun"
            }
            .map { it.text() }

        // then
        println("ğŸ“Š [AC3] ëª…ì‚¬ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        println("  - ì›ë³¸: \"$text\"")
        println("  - ì¶”ì¶œëœ ëª…ì‚¬: $nouns")

        assertThat(nouns).isNotEmpty
        assertThat(nouns).contains("ë”¥ëŸ¬ë‹", "ë¨¸ì‹ ëŸ¬ë‹", "ìì—°ì–´", "ì²˜ë¦¬", "ì‹œìŠ¤í…œ")
    }

    @Test
    @DisplayName("AC4: í˜¼í•© í…ìŠ¤íŠ¸(í•œêµ­ì–´+ì˜ì–´)ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤")
    fun `should handle mixed Korean and English text`() {
        // given
        val text = "GPUë¥¼ ì‚¬ìš©í•œ Deep Learning í•™ìŠµ ë°©ë²•"

        // when
        val normalized = OpenKoreanTextProcessorJava.normalize(text)
        val tokens = OpenKoreanTextProcessorJava.tokenize(normalized)

        val tokenList = scala.collection.JavaConverters.seqAsJavaList(tokens)
        val nouns = tokenList
            .filter { token ->
                val pos = token.pos().toString()
                pos == "Noun" || pos == "ProperNoun" || pos == "Alpha"
            }
            .map { it.text() }

        // then
        println("ğŸ“Š [AC4] í˜¼í•© í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:")
        println("  - ì›ë³¸: \"$text\"")
        println("  - ì¶”ì¶œëœ í† í°: $nouns")

        assertThat(nouns).isNotEmpty
        // í•œêµ­ì–´ ëª…ì‚¬ì™€ ì˜ì–´ ë‹¨ì–´ ëª¨ë‘ ì¶”ì¶œë˜ì–´ì•¼ í•¨
        assertThat(nouns).contains("í•™ìŠµ", "ë°©ë²•")
    }

    @Test
    @DisplayName("AC5: Open Korean Text ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    fun `performance test - tokenization should be fast`() {
        // given
        val text = "ìì—°ì–´ ì²˜ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ì˜ ì¤‘ìš”í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. " +
                "ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ìˆ ì´ ë°œì „í•˜ë©´ì„œ ë§ì€ ë°œì „ì´ ìˆì—ˆìŠµë‹ˆë‹¤."

        // warm-up
        repeat(5) {
            val normalized = OpenKoreanTextProcessorJava.normalize(text)
            OpenKoreanTextProcessorJava.tokenize(normalized)
        }

        // when - 100íšŒ ë°˜ë³µ
        val times = mutableListOf<Long>()
        repeat(100) {
            val start = System.currentTimeMillis()
            val normalized = OpenKoreanTextProcessorJava.normalize(text)
            OpenKoreanTextProcessorJava.tokenize(normalized)
            val end = System.currentTimeMillis()
            times.add(end - start)
        }

        // then
        val avgTime = times.average()
        val minTime = times.minOrNull() ?: 0
        val maxTime = times.maxOrNull() ?: 0

        println("ğŸ“Š [AC5] í˜•íƒœì†Œ ë¶„ì„ ì„±ëŠ¥:")
        println("  - í‰ê·  ì‹œê°„: ${avgTime}ms")
        println("  - ìµœì†Œ ì‹œê°„: ${minTime}ms")
        println("  - ìµœëŒ€ ì‹œê°„: ${maxTime}ms")
        println("  - ì°¸ê³ : ì„ë² ë”© ì‹œê°„(50ms)ê³¼ ë…ë¦½ì ")

        // í˜•íƒœì†Œ ë¶„ì„ì€ 10ms ì´ë‚´ ëª©í‘œ
        assertThat(avgTime).isLessThanOrEqualTo(10.0)
    }
}
